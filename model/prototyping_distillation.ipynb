{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "import numpy as np\n",
    "import meshio\n",
    "\n",
    "from torchmcubes import marching_cubes, grid_interp\n",
    "\n",
    "import distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andrewhc\\AppData\\Local\\Temp\\ipykernel_20892\\633730493.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  nsr = torch.load(\"nsr000.pt\")\n"
     ]
    }
   ],
   "source": [
    "nsr = torch.load(\"nsr000.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fg_sdf = nsr[\"s.fg_sdf\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verts, faces = marching_cubes(fg_sdf, thresh=0.0)\n",
    "\n",
    "# # removes duplicate vertices\n",
    "# verts, reverse_ind = torch.unique(verts, dim=0, return_inverse=True)\n",
    "# faces = reverse_ind[faces]\n",
    "\n",
    "verts, faces = distillation.compute_mesh(fg_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh = meshio.Mesh(\n",
    "    verts.detach().cpu().numpy().tolist(),\n",
    "    [(\"triangle\", faces.detach().cpu().numpy().tolist())]  # + albedo (color) & roughness\n",
    ")\n",
    "mesh.write(\"calculator.obj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal = torch.zeros(verts.shape)\n",
    "albedo = torch.ones(verts.shape[0])  # parameter\n",
    "roughness = torch.ones(verts.shape[0])  # parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6484, -3.1133],\n",
       "        [ 1.5569,  2.9234],\n",
       "        [ 1.1659,  3.0829],\n",
       "        ...,\n",
       "        [ 1.0511,  0.1610],\n",
       "        [ 1.3887,  0.5361],\n",
       "        [ 1.5682, -0.1042]], device='cuda:0')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Fx(A,B,C) -> Fx(A,B,C)x(X,Y,Z)\n",
    "# vf = verts[faces]\n",
    "# face_norm = torch.linalg.cross(vf[:,1]-vf[:,0], vf[:,2]-vf[:,0])\n",
    "\n",
    "# # index_put_: supports simulataneous summation for duplicate indices in faces\n",
    "# vert_norm = torch.zeros(verts.shape, device=\"cuda\")\n",
    "# vert_norm.index_put_(indices=(faces.flatten(),),\n",
    "#                      values=torch.repeat_interleave(face_norm, 3, dim=0),\n",
    "#                      accumulate=True)\n",
    "# vert_norm = F.normalize(vert_norm)\n",
    "distillation.compute_normal(verts, faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9966, -0.0775, -0.0282],\n",
       "        [-0.9762,  0.0139,  0.2164],\n",
       "        [-0.9176,  0.3939,  0.0539],\n",
       "        ...,\n",
       "        [ 0.8568,  0.4966,  0.1391],\n",
       "        [ 0.8455,  0.1811,  0.5023],\n",
       "        [ 0.9946,  0.0025, -0.1040]], device='cuda:0')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vert_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.6484, -3.1133],\n",
       "        [ 1.5569,  2.9234],\n",
       "        [ 1.1659,  3.0829],\n",
       "        ...,\n",
       "        [ 1.0511,  0.1610],\n",
       "        [ 1.3887,  0.5361],\n",
       "        [ 1.5682, -0.1042]], device='cuda:0')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([\n",
    "    # THETA\n",
    "    torch.acos(vert_norm[:,1] / torch.linalg.norm(vert_norm, dim=1)),  #*(180.0/np.pi)\n",
    "    # PHI\n",
    "    torch.sign(vert_norm[:,2])*torch.acos(vert_norm[:,0] / torch.linalg.norm(vert_norm[:,[0,2]], dim=1)),   #*(180.0/np.pi)\n",
    "], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3643, 3]),\n",
       " torch.Size([3643, 3]),\n",
       " torch.Size([3643]),\n",
       " torch.Size([3643]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verts.shape, vert_norm.shape, albedo.shape, roughness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_params = torch.ones((256, 6), device=\"cuda\")  # 256x[R,G,B,λ,θp,φp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "θp, φp = sg_params[:, 4], sg_params[:, 5]\n",
    "spherical_dot = lambda θv, φv: torch.sin(θv)*torch.sin(θp)*torch.cos(φv-φp)+torch.cos(θv)*torch.cos(θp)\n",
    "# (sg_params[:, 4:6]*torch.tensor([-1,5], device=\"cuda\")).sum(axis=1)\n",
    "\n",
    "lights = lambda θv, φv: sg_params[:, 0:3]*torch.exp(sg_params[:, 3]*(spherical_dot(θv, φv)-1))[:, torch.newaxis]\n",
    "\n",
    "result = lights(\n",
    "    torch.tensor(-1, device=\"cuda\"),\n",
    "    torch.tensor(5, device=\"cuda\"),\n",
    ").sum(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([200.3231, 200.3231, 200.3231], device='cuda:0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548, 0.7548,\n",
       "        0.7548, 0.7548, 0.7548, 0.7548], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θp, φp = sg_params[:, 4], sg_params[:, 5]\n",
    "spherical_dot = lambda θv, φv: torch.sin(θv)*torch.sin(θp)*torch.cos(φv-φp)+torch.cos(θv)*torch.cos(θp)\n",
    "# (sg_params[:, 4:6]*torch.tensor([-1,5], device=\"cuda\")).sum(axis=1)\n",
    "spherical_dot(torch.tensor(-1, device=\"cuda\"), torch.tensor(5, device=\"cuda\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1.], device='cuda:0'),\n",
       " tensor([0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081, 0.7081,\n",
       "         0.7081, 0.7081, 0.7081, 0.7081], device='cuda:0'))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "θp, torch.sin(θp)*torch.sin(θp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
